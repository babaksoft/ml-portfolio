{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29a503c9-593e-4701-8cc7-9f6de61a87b5",
   "metadata": {},
   "source": [
    "# Unsupervised Machine Learning - Clustering\n",
    "\n",
    "This is the final assessment project for course 4 of [IBM Machine Learning Specialization](https://www.coursera.org/specializations/ibm-machine-learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74981d86-0358-4414-b821-9d7e5a8142c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# About the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc6a403-9c54-4f0f-aa53-2a9063065235",
   "metadata": {},
   "source": [
    "We'll be working with [Travel Reviews](https://archive.ics.uci.edu/dataset/484/travel+reviews) dataset provided by [UCI Machine Learning Repository](https://archive.ics.uci.edu/). This data set is populated by crawling TripAdvisor.com and it represents aggregated user ratings on various categories, ranging from restaurants and juice bars to museums and religious institutions. Each data instance represents user ratings for a specific travel destination in East Asia, averaged for each category. Each traveler rating is mapped as Excellent (4), Very Good (3), Average (2), Poor (1), and Terrible (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0be40c-a5af-4d13-a4a3-d546b7e538ac",
   "metadata": {},
   "source": [
    "In the original dataset, category features are labeled using generic names (Category 1, Category 2, etc.) and as a first step, original labels were replaced by with more descriptive names, guided by dataset description."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5dc033-39ef-4130-9d15-14691cea476b",
   "metadata": {},
   "source": [
    "## Dataset Features\n",
    "\n",
    "*Note : The labels inside parenthesis represent new feature names.*\n",
    "\n",
    "- User ID : User identifier in string form (e.g. 'User 123')\n",
    "- Category 1 : Average user feedback on art galleries (art_galleries)\n",
    "- Category 2 : Average user feedback on dance clubs (dance_clubs)\n",
    "- Category 3 : Average user feedback on juice bars (juice_bars)\n",
    "- Category 4 : Average user feedback on restaurants (restaurants)\n",
    "- Category 5 : Average user feedback on museums (museums)\n",
    "- Category 6 : Average user feedback on resorts (resorts)\n",
    "- Category 7 : Average user feedback on parks/picnic spots (parks_picnic)\n",
    "- Category 8 : Average user feedback on beaches (beaches)\n",
    "- Category 9 : Average user feedback on theaters (theaters)\n",
    "- Category 10 : Average user feedback on religious institutions (religious_inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e08026-e5d0-4a68-9e4f-061432bf8dbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dfe700-41fc-4993-aed1-9700379b2708",
   "metadata": {},
   "source": [
    "ABC Company is experiencing a constant decline in sales figures of travel packages for East Asia. Intimidated by most competitors' clever use of AI-powered strategies, the company has hired a small Data Science team to figure out a solution. With a strong motivation to shine in the new department, the team gets busy with scraping user rating pages in tripadvisor.com and comes up with a promising dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3924f2d-4292-44e8-bcc6-c0918bf9a7af",
   "metadata": {},
   "source": [
    "Stakeholders at ABC company aren't that impressed, but decide to give their new team a chance. They state some goals and objectives for a new pilot project. The project requirements are summarized below:\n",
    "\n",
    "1. Using clustering analysis on Travel Reviews dataset, segment travelers based on common tastes and interests.\n",
    "2. Domain experts will use these segments to design brand new travel packages, tailored to each segment.\n",
    "3. Final clusters can have different sizes, but keep the count small (4-7 clusters would be nice).\n",
    "4. The main priority is boosting package sales and getting high customer ratings, so focus on ordinary travelers and ignore possible outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63235c53-a644-4ee2-ae82-f2665308a6d4",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73edf89-a3af-40d5-84b8-8e54e56a76c4",
   "metadata": {},
   "source": [
    "In this project, we'll be using Numpy, Pandas, Matplotlib, Seaborn and Scikit-Learn, all of which should normally be installed\n",
    "in any Python Machine Learning environment.\n",
    "\n",
    "Please run the following cells to prepare our modeling environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2b79a-ad29-40a4-adcb-0f31e78ecb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans, MeanShift, DBSCAN, estimate_bandwidth\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef2ab4-b251-46fd-9d3f-2efd8e43d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find highest pair-wise correlations and return as a Pandas DataFrame\n",
    "def get_high_corr_df(corr_df):\n",
    "\n",
    "    # Disable self correlations for the upcoming examination\n",
    "    for col in corr_df.columns:\n",
    "        corr_df.loc[col,col] = 0.0\n",
    "\n",
    "    # Build a DataFrame from the highest pair-wise correlations\n",
    "    corr_maps = []\n",
    "    indices = np.argmax(corr_df.abs(), axis=1)\n",
    "    for i in range(len(indices)):\n",
    "        corr_map = pd.Series({'High_Corr_Col': str(corr_df.columns[indices[i]]),\n",
    "                              'High_Corr_Val': float(corr_df.iloc[i, indices[i]])})\n",
    "        corr_maps.append(corr_map)\n",
    "\n",
    "    high_corr_df = pd.DataFrame(pd.concat(corr_maps, axis=1).T)\n",
    "    high_corr_df.index = list(corr_df.columns)\n",
    "    return high_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc9a85-c4ad-4c74-a4b4-b4b6baf48757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a random state for repeatability\n",
    "rs = 147\n",
    "\n",
    "# Load Obesity dataset from current directory into a Pandas DataFrame\n",
    "df = pd.read_csv('tripadvisor_review.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da8fb77-aced-4db5-9e2a-b205897ad26b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb20bc4-b83f-4b6a-afba-96c69ec048a0",
   "metadata": {},
   "source": [
    "To get familiar with important dataset characteristics, an exhaustive data analysis was made before preparing dataset for modeling. The following sections briefly summarize the results of this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62a139-45db-44e5-b39c-0eb615dee402",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Initial data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f80803e-2401-45af-9d1d-6721a0bb0337",
   "metadata": {},
   "source": [
    "Preliminary examination of the dataset revealed the following characteristics :\n",
    "\n",
    "- Dataset has 980 instances, so it's not a large dataset and training will be relatively fast in all models.\n",
    "- All features are floating point numbers (float64) rounded to 2 decimal points, except the first feature (User ID).\n",
    "- Dataset has 10 numeric features with generic names (e.g. Category 1), meaning we should probably use more descriptive feature names prior to data analysis.\n",
    "- Dataset does not have missing values in any feature, so data imputing is not required.\n",
    "- Being averaged from integer values between 0 and 4, most numeric features have fairly similar value ranges.\n",
    "- Despite similar ranges in numeric features, scaling is required due to some features having small ranges (Category 7, Category 8 and Category 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d588e193-81fd-4828-ac28-3f334337078b",
   "metadata": {},
   "source": [
    "Please run the following cells for a demonstration of these characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f4cff-e8c4-4f9e-926e-f6db8d4c839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview a random sample of instances\n",
    "df.sample(5, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d795d8-6baa-4381-a5f9-d28e7eacfe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out dataset shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a489ab7-d719-4226-83e5-7599b8345aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a brief overview of data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5178aa6-1759-4bfc-a5d0-fc5a121879dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840b643-94be-49f5-9488-45ffce21c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex numeric features with descriptive names\n",
    "df.columns = pd.Index(['User ID', 'art_galleries', 'dance_clubs', 'juice_bars', 'restaurants', 'museums',\n",
    "                       'resorts', 'parks_picnic', 'beaches', 'theaters', 'religious_inst'])\n",
    "df.sample(5, random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c5ccf-91a6-41fa-83e2-14d55d10a751",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Correlation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ee0c89-c482-4073-94e7-bf744ae7417e",
   "metadata": {},
   "source": [
    "Correlation analysis revealed that some significant feature correlations exist. The clusters identified by our final model may (or may not) reflect some insights about this. But it's important to keep a record of these correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3696bf-79aa-4462-bc2e-ef533c86afc5",
   "metadata": {},
   "source": [
    "Please run the following cells to see the results of correlation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e99419-dae8-4e2b-aef7-d2bbd0dccd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out all feature correlations \n",
    "corr_mat = df.corr(numeric_only=True)\n",
    "corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7350db8f-2304-4dd0-b58e-093389e4bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out highest pair-wise correlations\n",
    "high_corr_df = get_high_corr_df(corr_mat)\n",
    "high_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d888b71-2c00-45b3-a1d5-a481a487339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's filter significant correlations (corr > 0.5)\n",
    "high_corr_df[abs(high_corr_df.High_Corr_Val) > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593012f6-0899-48ef-ae4d-eb7927ebc8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize high correlations in a pair plot\n",
    "high_corr_cols = ['juice_bars', 'parks_picnic', 'museums', 'resorts', 'religious_inst']\n",
    "\n",
    "sns.pairplot(df[high_corr_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12ecf25-93c0-4453-8b9c-4d0006428a0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Normality analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ac7302-4053-438a-aa58-fd6727fde07f",
   "metadata": {},
   "source": [
    "Distribution of a couple of features in this dataset is highly skewed and, according to the standard skewness threshold (0.75), half of the features are technically skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a413e54-8fc7-4bcf-af8e-76a60df9fcb0",
   "metadata": {},
   "source": [
    "Please run the following cells to examine the most skewed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d0309-4ab1-45ee-8d32-d18c67b9a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all features that have significant skewness (> 0.75)\n",
    "skew_vals = df.iloc[:, 1:].skew()\n",
    "skew_cols = skew_vals[abs(skew_vals) > 0.75]\n",
    "skew_cols.sort_values(ascending=False).to_frame().rename({0: 'skew'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532fafc9-2d71-43fc-8144-831088f14880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize different skew levels using histograms\n",
    "_, axes_ = plt.subplots(2, 3, figsize=(6, 4))\n",
    "axes = axes_.flatten()\n",
    "\n",
    "for i, col in enumerate(skew_cols.index):\n",
    "    axes[i].hist(df[col], bins=20)\n",
    "    axes[i].set(xlabel=col, ylabel='Frequency')\n",
    "\n",
    "axes[5].remove()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f513d9-47ca-47e5-905c-f1cdec235044",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Outlier analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439858de-ff89-4838-9924-69a678137634",
   "metadata": {},
   "source": [
    "Since we're doing clustering analysis in this project, we're dealing with two types of outliers, both of which don't merit further action :\n",
    "\n",
    "- Outliers in feature values : All features have a limited (small) range and we're going to remove skewness at feature engineering stage.\n",
    "- Outliers in clusters : Although DBSCAN will detect any possible outliers, the ABC company is more focused on travel package sales and high satisfaction rate from generic customers. So there is no specific plan for picky customers that may be hard to please."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af5167-3fb0-483f-9872-e72fe344e2bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Feature selection and engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c21734-2484-45aa-ac33-9070a651d0b0",
   "metadata": {},
   "source": [
    "Our exploratory data analysis revealed the need for several data preparation steps. These steps are summarized below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71253c2c-1e54-412b-a452-30b709d40a2e",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "The User ID feature was removed, as it doesn't have any modeling value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485fe813-c6d8-44a7-a88a-7c3bc42fa708",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Feature engineering\n",
    "\n",
    "- All features were renamed according to the main dataset description. This step was performed prior to data analysis.\n",
    "- All feature values were scaled using MinMaxScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c746c0b-2374-40e1-8696-a85c5ba4182f",
   "metadata": {},
   "source": [
    "Please run the following cells to see how the above steps were done in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df2ee6-478d-4550-be66-a267e1429463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the original data and use it for data preprocessing\n",
    "data = df.copy()\n",
    "\n",
    "data = data.drop(['User ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd2d64-75ce-4080-aed4-4670207bb390",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data[data.columns] = scaler.fit_transform(data[data.columns])\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8046fab6-b0d1-421f-a3be-f8a7ddcc77c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Clustering models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec74e42e-bc7a-4ea7-a400-6f8597b62fa4",
   "metadata": {},
   "source": [
    "In order to find the suitable number of clusters suggested by business objectives (i.e. 4-7) several models were trained. Modeling steps can be summarized as follows.\n",
    "\n",
    "- A range of cluster counts (from 2 to 10) were used to train several K-Means models. Using the Elbow Method, the optimal cluster count was estimated.\n",
    "- A wide range of epsilon and n_clu values were using to train several DBSCAN models. The counts of clusters and outliers were aggregated and the best model was sought based on arbitrary criteria : n_clusters < 10 and n_outliers < 10 (roughly 1% of all data points)\n",
    "- A single Mean Shift model was trained using the estimated bandwidth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f673be6-5ae8-41c1-9375-e2d663bff502",
   "metadata": {},
   "source": [
    "Please run the following cells to see the results obtained from different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c7e542-1ec7-4b0d-94e7-98f684a5b303",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5d28dc-1a10-46a5-8deb-2f48a5a5fd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train several K-Means models and aggregate results\n",
    "k_max = 10\n",
    "km_list = []\n",
    "\n",
    "for k in range(2, k_max+1):\n",
    "    km = KMeans(n_clusters=k, random_state=rs)\n",
    "    km = km.fit(X)\n",
    "    km_list.append(pd.Series({'K': k, 'Inertia': km.inertia_}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089db449-6e81-43e2-9c03-d859191b73b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use elbow method to find the best model\n",
    "km_df = pd.concat(km_list, axis=1).T.set_index('K')\n",
    "ax = km_df.plot(marker='o', ls='-')\n",
    "ax.set(xlabel='Clusters', ylabel='Inertia')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f1798d-b8ad-4389-8b6a-bb0057a70ce6",
   "metadata": {},
   "source": [
    "As shown in the above plot, an obvious inflection point cannot be estimated. However, to better align with our business objectives, we're going to choose K = 6 as our best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcb8408-8653-4387-b51f-1d05213b0bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_best = KMeans(n_clusters=7, random_state=rs).fit(X)\n",
    "\n",
    "print(f'Best K-Means : K = 7, Inertia = {round(km_best.inertia_, 4)}')\n",
    "km_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab141c44-1f6f-40b9-b4d2-d1ca56b05351",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da385660-c4ce-4610-a882-320a75f67968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train several DBSCAN models and aggregate results\n",
    "eps_vals = [i*0.001 for i in range(1, 21)]\n",
    "n_clus = [2, 3]\n",
    "dbs_result = []\n",
    "\n",
    "for eps in eps_vals:\n",
    "    for min_samples in n_clus:\n",
    "        dbs = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        dbs = dbs.fit(X)\n",
    "        dbs_result.append(pd.Series({'eps': eps, 'n_clu': min_samples,\n",
    "                                     'clusters': len(set(dbs.labels_[dbs.labels_ >= 0])),\n",
    "                                     'outliers': abs(dbs.labels_[dbs.labels_ == -1].sum())}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b3323b-8d84-4d19-a10c-89fa18c260b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Pandas DataFrame from aggregated results\n",
    "dbs_df = pd.concat(dbs_result, axis=1).T\n",
    "dbs_df.index = pd.Index([f\"({round(eps, 4)}, {n_clu})\" for eps, n_clu in zip(dbs_df['eps'], dbs_df['n_clu'])],\n",
    "                        name='(eps, n_clu)')\n",
    "dbs_df = dbs_df.drop(columns=['eps', 'n_clu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2406e2-0178-43f8-98f6-4e498d4f7566",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce891027-e53c-4465-891e-39a7d959ad4a",
   "metadata": {},
   "source": [
    "One can verify from the above (sample) results that DBSCAN cannot lead to optimal clusters with this dataset. This can be due to the infamous Curse of Dimensionality. Many ranges of smaller *epsilon* values were also used, always with similar results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac7ae57-c226-4f13-adef-345875e21db2",
   "metadata": {},
   "source": [
    "Ultimately with current dataset shape, DBSCAN fails to provide good results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f07219e-0e1a-4ba4-8f33-60ace0d4d9e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db355aa-4c33-4792-aa8f-e36de505d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Mean Shift model to our dataset and display clustering result\n",
    "bandwidth = estimate_bandwidth(X)\n",
    "mshift = MeanShift(bandwidth=bandwidth, bin_seeding=True, cluster_all=False)\n",
    "mshift = mshift.fit(X)\n",
    "\n",
    "n_clusters = len(set(mshift.labels_[mshift.labels_ >= 0]))\n",
    "n_outliers = abs(mshift.labels_[mshift.labels_ == -1].sum())\n",
    "\n",
    "print(f'Mean Shift found {n_clusters} clusters and marked {n_outliers} data points as noise.')\n",
    "mshift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2581573e-c2bd-4520-9d28-d32ce5c0608c",
   "metadata": {},
   "source": [
    "Comparing our business objectives and the result shown above, we can verify that Mean Shift found too few clusters and too many outliers. So our Mean Shift model is not acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd5d1fe-1450-4ce9-923e-550e510f5ff1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae64eb-c1b7-4a1b-a9d8-2397af56f200",
   "metadata": {},
   "source": [
    "Based on the above analysis, our best clustering model is **K-Means with 6 clusters**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c48654-b45d-4e20-a4e7-6dc96f5c2163",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Insights and key findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5995ea-1917-4266-b789-817cd209a83b",
   "metadata": {},
   "source": [
    "After training different models and comparing results, we can make some notes about the quality of our modeling workflow and hidden patterns in this dataset.\n",
    "\n",
    "- Several high correlations between some features may have degraded the overall performance of our models. Also, repeating the process after transforming skewed features may lead to better results in all models.\n",
    "- K-Means model resulted in a final model that aligns well with our business objectives. However, with a 10-dimensional feature space, we can't get a sufficiently accurate visual cue about the shape and density of final clusters.\n",
    "- Thinking about the inner logic of DBSCAN clustering, the constant output of the algorithm may be due to varying cluster densities in the dataset. Also, high dimensionality of our dataset may force data points to appear too far apart to distance-based algorithms. Repeating the process with lower dimensions (2D or 3D) may be worth trying.\n",
    "- As implemented in Scikit-Learn, the Mean Shift model doesn't allow hyperparameter tuning and we're forced to stick with a single estimated bandwidth. To get the most out of this model, some more study and research may be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c99b97b-6497-4d11-ada9-468e5e31964b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565218a4-4a18-464c-a082-d6a9563dc88e",
   "metadata": {},
   "source": [
    "Based on the trained models and data preprocessing steps, we may be able to improve data quality and plan for some more experiments. Hopefully, these actions will lead to models that perform better and make room for easier interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1500eb0-efb6-47db-b0c9-e36228065f6c",
   "metadata": {},
   "source": [
    "## Possible faults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1437119a-004c-4268-9c3d-d10355da7c75",
   "metadata": {},
   "source": [
    "No dimensionality reduction was incorporated in our data preprocessing. This may be vital for the following reasons:\n",
    "\n",
    "- Our dataset may be noisy and it's usually good practice to apply techniques like PCA analysis before modeling.\n",
    "- Because most clustering algorithms are distance-based, using a small feature space may provide much better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab620c59-e217-414c-89a3-fb5e7b149dab",
   "metadata": {},
   "source": [
    "## Action plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100893e8-ca70-4bf0-b935-b2018ee34434",
   "metadata": {},
   "source": [
    "Repeating the whole modeling with a more carefully refined dataset is definitely worth trying. The following actions can be taken to improve our preprocessing pipeline:\n",
    "- Apply PCA with a range of components to account for high correlations and possible noise.\n",
    "- To enable cluster visualization, prefer a PCA transform with 2 or 3 components.\n",
    "- Try other approaches, like Multi-Dimensional Scaling (MDS), to shrink dataset’s feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b82fd85-45aa-4a92-9aca-40c873829ae1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Acknowledgements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ad192-b309-4e23-99d5-0aaa37bb134f",
   "metadata": {},
   "source": [
    "Thank you so much for taking the time to review and grade this project.\n",
    "\n",
    "I’d also like to thank our brilliant instructors (especially Dr. Joseph Santarcangelo) for their excellent learning materials. It’s been a real pleasure taking this course."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
