{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29a503c9-593e-4701-8cc7-9f6de61a87b5",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning - Classification\n",
    "\n",
    "This is the final assessment project for course 3 of [IBM Machine Learning Specialization](https://www.coursera.org/specializations/ibm-machine-learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74981d86-0358-4414-b821-9d7e5a8142c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# About the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245feb10-b251-417b-95d1-3bdafcf1de9c",
   "metadata": {},
   "source": [
    "We'll be working with [Obesity](https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition)\n",
    "dataset provided by [UCI Machine Learning Repository](https://archive.ics.uci.edu/). This dataset includes data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia.\n",
    "\n",
    "Using an online survey, data has been collected regarding each participant's eating and drinking habits, as well as their overall lifestyle. Based on the answers, an obesity level was estimated for each person."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4298e6be-2ba9-4147-ad84-842113f5b40c",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "- Gender : (Male/Female)\n",
    "- Age : Person's age\n",
    "- Height : Person's height, in meters\n",
    "- Weight : Person's weight, in kilograms\n",
    "- family_history_with_overweight : Has a family member suffered or suffers from overweight? (yes/no)\n",
    "- FAVC : Do you eat high caloric food frequently? (yes/no)\n",
    "- FCVC : Do you usually eat vegetables in your meals? (numeric)\n",
    "- NCP : How many main meals do you have daily? (numeric)\n",
    "- CAEC : Do you eat any food between meals? (ordinal)\n",
    "- SMOKE : Do you smoke? (yes/no)\n",
    "- CH2O : How much water do you drink daily? (numeric)\n",
    "- SCC : Do you monitor the calories you eat daily? (yes/no)\n",
    "- FAF : How often do you have physical activity? (numeric)\n",
    "- TUE : How much time do you use technological devices such as cell phone, videogames, television, computer and others? (numeric)\n",
    "- CALC : How often do you drink alcohol? (ordinal)\n",
    "- MTRANS : Which transportation do you usually use? (nominal)\n",
    "- NObeyesdad : Obesity level (target class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e08026-e5d0-4a68-9e4f-061432bf8dbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e74d9d-dfcf-4c08-a0f6-f20baa744fe8",
   "metadata": {},
   "source": [
    "Having more than 2 class labels, this dataset requires multi-class classification to predict one of the following obesity levels :\n",
    "\n",
    "- Insufficient Weight\n",
    "- Normal Weight\n",
    "- Overweight Level I\n",
    "- Overweight Level II\n",
    "- Obesity Type I\n",
    "- Obesity Type II\n",
    "- Obesity Type III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc68c7e-fc5a-451f-8409-864ce0cd03b1",
   "metadata": {},
   "source": [
    "The objectives for this project can be summarized as follows :\n",
    "\n",
    "- Using dataset features to predict obesity level for a new person. This can be helpful as some kind of preliminary medical assessment.\n",
    "- Using model interpretation techniques to gain insights about most important features that may help avoiding overweight/obesity disorders.\n",
    "- Building a model with a minimum baseline performance : Accuracy score >= 97%, F1 score >= 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570d9c1a-3116-4274-affb-58d834771942",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316aec3-50b4-43f2-bf86-48f5f10e9559",
   "metadata": {},
   "source": [
    "In this project, we'll be using Numpy, Pandas, Matplotlib, Seaborn and Scikit-Learn, all of which should normally be installed\n",
    "in any Python Machine Learning environment.\n",
    "\n",
    "Please run the following cells to prepare our modeling environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64d54b8-d670-4c48-abda-56639df14df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d117940f-d394-4da2-9a34-20f049a72c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a random state for repeatability\n",
    "rs = 14741\n",
    "\n",
    "# Load Obesity dataset from current directory into a Pandas DataFrame\n",
    "df = pd.read_csv('obesity.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da8fb77-aced-4db5-9e2a-b205897ad26b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ec009c-661e-4511-b908-de0b513be3f8",
   "metadata": {},
   "source": [
    "To get familiar with important dataset characteristics, an exhaustive data analysis was made before preparing dataset for modeling. The following sections briefly summarize the results of this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62a139-45db-44e5-b39c-0eb615dee402",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Initial data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf18408-62ab-4a68-892d-a4a9346bcb74",
   "metadata": {},
   "source": [
    "Preliminary examination of the dataset revealed the following characteristics :\n",
    "\n",
    "- Dataset has 2111 instances, so it is rather small and using all instances in a 70/30 or 80/20 split will not slow down most learning algorithms.\n",
    "- Dataset has 16 features, half numerical and half categorical.\n",
    "- Dataset has all kinds of categorical features, namely: binary (yes/no), ordinal and nominal.\n",
    "- Dataset has no missing values in any features, so no data imputing will be required later.\n",
    "- Summary statistics of numeric features shows different value ranges, meaning we should probably scale them to improve performance and stability of linear (e.g., Logistic Regression) and distance-based (e.g., KNN and Linear SVC) models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909804d-a87d-4ba2-aca2-2e79bb98f5c0",
   "metadata": {},
   "source": [
    "Please run the following cells for a demonstration of these characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30baf5a9-19ac-4669-afb7-a690076c7f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview a random sample of instances\n",
    "df.sample(5, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e231832b-12cc-4eba-bb1d-15b95eac3757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out dataset shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bbfd18-95e2-41b6-9689-f9e8202545d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a brief overview of data types\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e0f36-0764-45c7-8e2c-86074b1b0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an initial feeling of how much feature engineering we need later\n",
    "df.select_dtypes(['object']).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ed26a-0912-49c8-91ef-705fe3f4f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out unique values in non-binary categorical features\n",
    "print(f'Unique values in CAEC feature :\\t\\t{list(df['CAEC'].unique())}')\n",
    "print(f'Unique values in CALC feature :\\t\\t{list(df['CALC'].unique())}')\n",
    "print(f'Unique values in MTRANS feature :\\t{list(df['MTRANS'].unique())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c289622-264f-4ed3-aad1-b53a491ba8ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Class balance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab822d55-fda3-44af-a07a-f8220afcb028",
   "metadata": {},
   "source": [
    "Description provided by the dataset donor states that this dataset includes both real and synthetic data, meaning class labels in original data has been explicitly balanced using a specific form of SMOTE resampling.\n",
    "\n",
    "Please run the following cells to see the breakdown of class labels in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5f30c7-42e4-462e-9920-6fc360d86e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakdown of class labels (count)\n",
    "df['NObeyesdad'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49720a0-aadc-4b69-aeaf-cacc436a0035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakdown of class labels (proportion)\n",
    "df['NObeyesdad'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e9185-f653-418c-a704-785eba6a624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of class label balance in a bar plot\n",
    "df['NObeyesdad'].value_counts(normalize=True).plot.bar(\n",
    "    color=['yellow', 'red', 'orange', 'pink', 'magenta', 'green', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c5ccf-91a6-41fa-83e2-14d55d10a751",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Correlation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cecbee-3992-4546-bc67-571ba445d2cb",
   "metadata": {},
   "source": [
    "Correlation analysis using numeric features revealed that no significant correlation exists between these features. The highest positive correlation value (0.46) exists between Height and Weight, which seems almost natural except in the most extreme cases (e.g. a very tall underweight or a very short overweight person)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb165430-8fbc-4a1a-b388-915b88d76b46",
   "metadata": {},
   "source": [
    "Please run the following cells to see the results of correlation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c51b198-d377-4c71-a91f-2e666effb23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = df.corr(numeric_only=True)\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e463c5-2b85-4504-b6d4-94978a8cc5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable self correlations for the upcoming examination\n",
    "for col in corr_df.columns:\n",
    "    corr_df.loc[col,col] = 0.0\n",
    "\n",
    "# Build a DataFrame from the highest pair-wise correlations\n",
    "corr_maps = []\n",
    "indices = np.argmax(corr_df.abs(), axis=1)\n",
    "for i in range(len(indices)):\n",
    "    corr_map = pd.Series({'Corr_Col': str(corr_df.columns[indices[i]]), 'Corr_Val': float(corr_df.iloc[i, indices[i]])})\n",
    "    corr_maps.append(corr_map)\n",
    "\n",
    "high_corr_df = pd.DataFrame(pd.concat(corr_maps, axis=1).T)\n",
    "high_corr_df.index = list(corr_df.columns)\n",
    "high_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36305e49-08ff-4bbc-ab91-e3210f4f766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize highest correlation values in a partial pair plot\n",
    "sns.pairplot(df[['Age', 'Height', 'Weight', 'FAF', 'TUE']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12ecf25-93c0-4453-8b9c-4d0006428a0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Normality analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485302d-d4f5-4b01-988c-d548c84908bb",
   "metadata": {},
   "source": [
    "Distribution of most numeric features is fairly close to a normal distribution. Only two features (Age and NCP) have significant skewness (i.e., skew > 0.75). To improve performance of linear models like logistic regression, we may later consider transforming numeric features using a suitable transform (Log, Square Root or BoxCox).\n",
    "\n",
    "Please run the following cells to examine the most skewed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f296264-c1f1-46b5-83e7-cc46a6faca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a list of all features that have significant skewness (> 0.75)\n",
    "skew_vals = df.select_dtypes(['float64']).skew()\n",
    "skew_cols = skew_vals[abs(skew_vals) > 0.75]\n",
    "skew_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a12cf21-3430-4b17-8f68-8bbbe7a3ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the most skewed features in histograms\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "axes[0].hist(df['Age'], bins=15)\n",
    "axes[0].set(xlabel='Age', ylabel='Frequency')\n",
    "\n",
    "axes[1].hist(df['NCP'], bins=15)\n",
    "axes[1].set(xlabel='NCP', ylabel='Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af5167-3fb0-483f-9872-e72fe344e2bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Feature selection and engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6c618c-a0c2-45be-b75e-81f01ce6f2e5",
   "metadata": {},
   "source": [
    "Obesity dataset has different types of categorical features. The following steps summarize the feature selection/engineering approaches used for each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8542305-1767-4ad5-b2f6-1aa752ad9019",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "The MTRANS (means of transportation) feature was removed, for two reasons :\n",
    "\n",
    "- It doesn't seem to have useful information (other than Walking, the other values don't seem to contribute much to weight control)\n",
    "- Values don't imply any order and must be one-hot encoded, which adds several correlated features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffa08a7-41a5-45a3-b988-8f2d5bcf7497",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "\n",
    "- As a convenience, two features were renamed ('family_history_with_overweight' renamed to 'fam_history' and 'NObeyesdad' renamed to 'Obesity')\n",
    "- All binary features (Gender, FAVC, SMOKE, etc.) were encoded using LabelEncoder with values of 0 and 1.\n",
    "- Ordinal features (CAEC and CALC) were encoded with a custom mapping, using the obvious ordering implied by values : no (0), Sometimes (1), Frequently (2), Always (3)\n",
    "- Class labels were encoded using LabelEncoder with values from 0 to 6 (for 7 class labels)\n",
    "- Whenever required by a model, all features were scaled using MinMaxScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace81abd-25d8-460c-9c25-c2b7ab61c3f2",
   "metadata": {},
   "source": [
    "Please run the following cells to see how the above encodings were done in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba5c54-538b-4923-a750-78872eac133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of original data for later verification of encodings\n",
    "data = df.copy()\n",
    "\n",
    "data = data.drop(['MTRANS'], axis=1)\n",
    "\n",
    "# Rename selected feature names as a convenience\n",
    "data.columns = pd.Index([col.replace('family_history_with_overweight', 'fam_history')\n",
    "                     .replace('NObeyesdad', 'Obesity') for col in data.columns])\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78e18c0-253b-4339-967f-52b52c1e85ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup binary encoders with predefined values\n",
    "le_bin = LabelEncoder().fit(['no', 'yes'])\n",
    "le_gen = LabelEncoder().fit(['Female', 'Male'])\n",
    "\n",
    "# Setup a custom mapping for ordinal features\n",
    "freq_map = {'no': 0, 'Sometimes': 1, 'Frequently': 2, 'Always': 3}\n",
    "\n",
    "# Fit a label encoder to class labels\n",
    "le_class = LabelEncoder().fit(data['Obesity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63222c9a-8208-4214-b5ae-c18086079476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check encoded labels\n",
    "le_class.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692e330-9975-4b1d-a85a-8a59dea34866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features using previously fit encoders and our custom mapping\n",
    "bin_cols = ['fam_history', 'FAVC', 'SMOKE', 'SCC']\n",
    "ord_cols = ['CAEC', 'CALC']\n",
    "\n",
    "data.Gender = le_gen.transform(data.Gender)\n",
    "\n",
    "for col in bin_cols:\n",
    "    data[col] = le_bin.transform(data[col])\n",
    "\n",
    "for col in ord_cols:\n",
    "    data[col] = data[col].map(freq_map)\n",
    "\n",
    "# Encode class labels\n",
    "data['Obesity'] = le_class.transform(data['Obesity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dee527-952c-42b7-a1ab-ec1f8151b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out top instances in our fully processed dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef2e7d-1be2-4150-9c7e-8dfaacae412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the same top instances to verify encodings\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8046fab6-b0d1-421f-a3be-f8a7ddcc77c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84905d8-3046-462d-bf8b-3ea07f1c3f60",
   "metadata": {},
   "source": [
    "To reach the objectives of this project, several models were trained. The whole modeling process can be summarized in the following stages :\n",
    "\n",
    "- Train/Test split : The whole dataset was split into 70% train and 30% test sets, using stratification to maintain class balance.\n",
    "- Logistic regression : A pipeline was used to scale data before fitting the model. To avoid complications with l1_ratio parameter (used by ElasticNet regularization), 3 regularization modes (None, L1 and L2) were used while tuning the model with GridSearch.\n",
    "- Logistic regression : A separate model was trained with ElasticNet and was tuned using different L1/L2 ratios.\n",
    "- Support Vector Machines (SVM) : A pipeline was used to scale data before fitting the model. The model was tuned using different values for 'C' and 'kernel' hyperparameters.\n",
    "- Decision Tree : Trained and tuned a model using 'criterion', 'max_depth' and 'min_samples_leaf' hyperparameters. To achieve better interpretability, limited 'max_depth' values to 5.\n",
    "- Random Forest : Trained and tuned a model using 'n_estimators', 'criterion', 'max_depth' and 'max_features' hyperparameters. To achieve better interpretability, limited 'max_depth' values to 4.\n",
    "- Gradient Boosting : Trained and tuned a model using 'n_estimators', 'criterion', 'learning_rate' and 'max_features' hyperparameters.\n",
    "- Aggregated performance metrics of each (best) model for easier comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fd0014-b7c2-4794-b4a9-19dd326aeedd",
   "metadata": {},
   "source": [
    "Please run the following cells to see the results obtained from different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d220e23e-b77b-4f30-b451-41e51c5e9e7a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e5139c-e8af-42d0-afd7-bca12235ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "y = data['Obesity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=rs)\n",
    "\n",
    "print(f'Training dataset shape, X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "print(f'Testing dataset shape,  X_test:  {X_test.shape},  y_test:  {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d70b01-f80a-4441-8f17-161579790c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_f1_scores(model, X_trn, y_trn, X_tst, y_tst, model_name):\n",
    "    y_pred_trn = model.predict(X_trn)\n",
    "    y_pred_tst = model.predict(X_tst)\n",
    "    scores = pd.Series({'model': model_name,\n",
    "                        'train accuracy': accuracy_score(y_trn, y_pred_trn),\n",
    "                        'test accuracy' : accuracy_score(y_tst, y_pred_tst),\n",
    "                        'train f1 score': f1_score(y_trn, y_pred_trn, average='weighted'),\n",
    "                        'test f1 score' : f1_score(y_tst, y_pred_tst, average='weighted')})\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc7e97-0851-4897-8d29-eda50fbb41a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a9a9a5-0b06-48be-9324-9c7a6abb7902",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5dc9d-c551-4531-8ab7-f8ee389f5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = [('minmax', MinMaxScaler()), ('model', LogisticRegression(solver='saga', max_iter=5000, random_state=rs))]\n",
    "pipeline = Pipeline(pipe)\n",
    "\n",
    "param_grid = {'model__penalty': [None, 'l1', 'l2'],\n",
    "             'model__C': [1.0, 5.0, 10.0]}\n",
    "search_lr = GridSearchCV(estimator=pipeline, param_grid=param_grid, n_jobs=2, cv=5)\n",
    "search_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f42fe1b-a5cc-4cb9-9da4-f89c9faca8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7020ef40-1128-4cae-9d12-f49c62312638",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = search_lr.best_estimator_\n",
    "all_scores.append(get_accuracy_f1_scores(best_lr, X_train, y_train, X_test, y_test, 'Log. Regression'))\n",
    "all_scores[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c968e32-d4d1-4e95-b090-1a1789a04331",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Logistic Regression with ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9656ad28-2937-4f59-ba68-e687df79803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_enet = [('minmax', MinMaxScaler()), ('model', LogisticRegression(solver='saga', penalty='elasticnet', max_iter=1000, random_state=rs))]\n",
    "pipeline_enet = Pipeline(pipe_enet)\n",
    "\n",
    "param_grid = {'model__l1_ratio': [0.1, 0.2, 0.3, 0.5],\n",
    "             'model__C': [0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "search_enet = GridSearchCV(estimator=pipeline_enet, param_grid=param_grid, n_jobs=2, cv=5)\n",
    "search_enet.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d97d95-928b-4ce4-9472-e769e2a63b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_enet.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e473de5b-3c18-4f6b-a8a3-c5ceb36a099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_enet = search_enet.best_estimator_\n",
    "all_scores.append(get_accuracy_f1_scores(best_enet, X_train, y_train, X_test, y_test, 'LR ElasticNet'))\n",
    "all_scores[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c224b443-a05c-417f-a967-3c9f45cb162a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb950a4-410a-45a4-a845-7c03b26c78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svm = [('minmax', MinMaxScaler()), ('model', SVC(random_state=rs))]\n",
    "pipeline_svm = Pipeline(pipe_svm)\n",
    "\n",
    "param_grid = {'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "             'model__C': [1.0, 5.0, 10.0, 20.0, 50.0]}\n",
    "search_svm = GridSearchCV(estimator=pipeline_svm, param_grid=param_grid, n_jobs=2, cv=5)\n",
    "search_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90b874b-fcc2-4324-b334-e45953dd5b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a512c9-7379-4070-b105-6756abe8bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm = search_svm.best_estimator_\n",
    "all_scores.append(get_accuracy_f1_scores(best_svm, X_train, y_train, X_test, y_test, 'SVM'))\n",
    "all_scores[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4176e4a-b3a2-44e5-a627-b44d0f820b13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80e739c-93cc-4f31-933d-6905a79bfa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree = DecisionTreeClassifier(random_state=rs)\n",
    "param_grid = {'criterion': ['gini', 'entropy'],\n",
    "              'max_depth': [2, 3, 4, 5],\n",
    "              'min_samples_leaf': [2, 3, 4, 5]}\n",
    "search_tree = GridSearchCV(estimator=dec_tree, param_grid=param_grid, n_jobs=2, cv=5)\n",
    "search_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5b043-6cc9-41ea-bb34-76495efec133",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a7853-dca6-45da-93c9-ed1f07e567d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = search_tree.best_estimator_\n",
    "all_scores.append(get_accuracy_f1_scores(best_tree, X_train, y_train, X_test, y_test, 'Decision Tree'))\n",
    "all_scores[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375bb7f1-db8d-4a04-80ec-0ce391aef4d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e29ecc5-756c-4e23-b525-5a75f95ee82f",
   "metadata": {},
   "source": [
    "*Note : The following cell may take several minutes to complete.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d37325-2618-4382-b38e-c4499761eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=rs)\n",
    "param_grid = {'n_estimators': [20, 50, 100, 150, 200],\n",
    "              'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "              'max_depth': [2, 3, 4],\n",
    "              'max_features': [3, 4, 5, 'sqrt', 'log2']}\n",
    "search_rf = GridSearchCV(estimator=rf_clf, param_grid=param_grid, n_jobs=2, cv=5)\n",
    "search_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5d917c-1f14-46de-bb22-bab7ce127383",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1bc223-ca88-4322-9d44-c0185250b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = search_rf.best_estimator_\n",
    "all_scores.append(get_accuracy_f1_scores(best_rf, X_train, y_train, X_test, y_test, 'Random Forest'))\n",
    "all_scores[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee5eec3-cf73-4815-b360-43014cfdc873",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6300db-63c7-4c20-941d-aec263a63b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state=rs)\n",
    "param_grid = {'n_estimators': [5, 10, 15, 20],\n",
    "              'criterion': ['friedman_mse', 'squared_error'],\n",
    "              'learning_rate': [0.1, 0.15, 0.2],\n",
    "              'max_features': ['sqrt', 'log2']}\n",
    "search_gb = GridSearchCV(estimator=gb_clf, param_grid=param_grid, n_jobs=2, cv=5)\n",
    "search_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad09b6-8666-46a3-acb8-ad5ddeefb00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_gb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5209a12-c677-4a5e-ac34-ee2c1e5d3d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gb = search_gb.best_estimator_\n",
    "all_scores.append(get_accuracy_f1_scores(best_gb, X_train, y_train, X_test, y_test, 'Gradient Boosting'))\n",
    "all_scores[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1200a8-ba5e-4fdd-a2b1-64dbb459e037",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550008d7-3f9b-4583-be0e-04ad75d7d3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = pd.DataFrame(pd.concat(all_scores, axis=1)).T.set_index('model')\n",
    "perf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153a1b4-03f4-4c96-aa26-4dc99b2bfc6f",
   "metadata": {},
   "source": [
    "After training all models and aggregating important metrics, it’s time to choose the best model that will ultimately help us reach all objectives for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80219068-c5d0-4cca-93aa-d45d6b4eb699",
   "metadata": {},
   "source": [
    "We can make the following notes regarding the above performance summary:\n",
    "\n",
    "- The “LR ElasticNet”, “Decision Tree” and “Random Forest” models have inferior performance and will be discarded.\n",
    "- The “SVM” model’s performance is slightly lower than “Log. Regression” model, but since SVM is not sufficiently interpretable, it doesn’t fit project requirements.\n",
    "- As a tree-based model, “Gradient Boosting” has a high potential for interpretability, but it’s overfitting the data. It probably needs more careful tuning.\n",
    "\n",
    "Based on the above considerations, the winner is our “vanilla” **Logistic Regression** model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c48654-b45d-4e20-a4e7-6dc96f5c2163",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Insights and key findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4966f6-027a-4b23-8253-bd1f3300d66b",
   "metadata": {},
   "source": [
    "Although our final model provides excellent predictive results, it may not be suitable for interpretation. Because a Logistic Regression model may lead to an interpretable model if one or more of the following conditions are met:\n",
    "\n",
    "- We're dealing with a binary classification problem, where final model parameters (coefficients) may have a direct impact on positive or negative classes.\n",
    "- Dataset does not have too many features.\n",
    "- We can effectively utilize feature selection potentials in L1 regularization, without losing useful information in data.\n",
    "\n",
    "Our dataset is not feature-intensive (it has only 16 features), but even with this many features, we cannot leverage interpretability benefits of simple models like KNN. So, we may have to reconsider tree-based models like Decision Tree and Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c99b97b-6497-4d11-ada9-468e5e31964b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5680658b-93df-4918-a980-a9793f4cc01f",
   "metadata": {},
   "source": [
    "After going through this data analysis and model training experiment, it's time to contemplate about what we accomplished and how to proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dae310-1bef-48fe-b44a-00d4723ebe1b",
   "metadata": {},
   "source": [
    "## Possible flaws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b108ff-f55a-49c2-be4c-8e177a642f24",
   "metadata": {},
   "source": [
    "This project provided an excellent ground for experimenting with several classification models. However, one logical fault comes to mind :\n",
    "\n",
    "Regarding the basic requirement for model interpretability, we could have skipped some hard-to-interpret models (like SVM and Random Forest) altogether. This kind of smart choice will definitely save modeler's precious time in a real project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfaa641-6494-4446-ba2f-3d3214dae695",
   "metadata": {},
   "source": [
    "## Action plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688bfe11-24b3-4f67-8c92-36c38d724cc6",
   "metadata": {},
   "source": [
    "- Although our \"vanilla\" logistic regression model performed beyond expectations, one may consider training a KNN model, after applying PCA with a few components (3 or 4). This may lead to better model interpretability.\n",
    "- Although our decision tree model didn't beat baseline performance, one may consider more careful tuning of Gradient Boosting model, which may lead to a tree model that doesn't suffer overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b82fd85-45aa-4a92-9aca-40c873829ae1",
   "metadata": {},
   "source": [
    "# Acknowledgements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca40768a-2943-429b-9554-fa0ba11d4f81",
   "metadata": {},
   "source": [
    "Thank you so much for taking the time to review and grade this project.\n",
    "\n",
    "I’d also like to thank our brilliant instructors (especially Dr. Joseph Santarcangelo) for their excellent learning materials. It’s been a real pleasure taking this course.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
